{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning GPT-2 on a all recipes dataset in PyTorch\n",
    "\n",
    "\n",
    "\n",
    "#### If you haven't yet, check out the notebook in this [gist](https://gist.github.com/mf1024/430d7fd6ff527350d3e4b5bda0d8614e) where use the same pretrained model to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_from_top(probs, n=5):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
    "    choice = np.random.choice(n, 1, p = top_prob)\n",
    "    token_id = ind[choice][0]\n",
    "    return int(token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataset module for Short jokes dataset\n",
    "\n",
    "For fine-tuning the GPT2 model, I will use this [Short Jokes dataset](https://www.kaggle.com/abhinavmoudgil95/short-jokes) published on Kaggle. After each joke, I add \"<|endofext|>\" which is recognized by the GPT2 model as and end of text marker. The marker will allow me to concatenate many jokes in a single input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingredients(ingredients):\n",
    "    output = []\n",
    "    for ingredient in ingredients:\n",
    "#         values = removeChar(ingredient).split(\" \")\n",
    "#         values = values[1:]\n",
    "#         for volume in [\"\\u2009\"]:\n",
    "#             if volume in values: values.remove(volume)\n",
    "#         ingredient = \" \".join(values)\n",
    "        output.append(ingredient.replace(\"\\u2009\", ' '))\n",
    "    return output\n",
    "\n",
    "class RecipesDataset(Dataset):\n",
    "    def __init__(self, recipes_dataset_path = 'C:/Users/Mech Punk/Documents/crawler/allrecipes'):\n",
    "        super().__init__()\n",
    "\n",
    "        recipefiles = [f for f in listdir(recipes_dataset_path) if isfile(join(recipes_dataset_path, f))]\n",
    "\n",
    "        self.recipe_list = []\n",
    "        self.title_token = \"_tit\" #\"<|title|>\"\n",
    "        self.ingredients_token = \"_ing\" \n",
    "        self.instructions_token = \"_ins\" #\"<|instructions|>\"\n",
    "        self.review_token = \"_rev\" #\"<|review|>\"\n",
    "        self.rating_token = \"_rat\" #\"<|rating|>\"\n",
    "        self.end_of_text_token = \"_end\" #\"<|endoftext|>\"\n",
    "        self.categories_token = \"_cat\" #\"<|endoftext|>\"\n",
    "        \n",
    "        recipe_list = []\n",
    "        for recipefile in recipefiles:\n",
    "            path = os.path.join(recipes_dataset_path, recipefile)\n",
    "            with open(path) as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                for recipe in json_data:\n",
    "                    if \"Three Cheese Italian Style Chicken Sausage Skillet\" in recipe['title']:\n",
    "                        continue\n",
    "                    # Instructions\n",
    "                    if type(recipe[\"recipeInstructions\"]) != list:\n",
    "                        recipe[\"recipeInstructions\"] = [step[3:] for step in recipe[\"recipeInstructions\"].split(\"Step\")][1:]\n",
    "                    recipeInstructions = \"\"\n",
    "                    for step_index, step in enumerate(recipe[\"recipeInstructions\"]):\n",
    "                        recipeInstructions += f\"Step {step_index+1} \\n \" + step.replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
    "                    recipeInstructions = recipeInstructions.replace(\"\\n\", \" \\n \").replace(\"  \",\" \")\n",
    "                    # Ingredients\n",
    "                    ingredients = \"\"\n",
    "                    for ingredient in clean_ingredients(recipe[\"recipeIngredients\"]):\n",
    "                        ingredients += f\" \\n {ingredient}\"\n",
    "                    # Categories\n",
    "                    categories = \"\"\n",
    "                    for category in recipe[\"recipeCategory\"]:\n",
    "                        categories += f\" \\n {category}\"\n",
    "                    # Reviews\n",
    "                    for review in recipe[\"ratings\"]:\n",
    "                        text = review[\"text\"]\n",
    "                        value = review[\"value\"]\n",
    "                        recipe_str = f\"{self.title_token} {recipe['title']} {self.categories_token} {categories} {self.ingredients_token} {ingredients} {self.instructions_token} {recipeInstructions} {self.review_token} {text} {self.rating_token} {value} {self.end_of_text_token}\"\n",
    "                        self.recipe_list.append(recipe_str.replace(\"  \",\" \"))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.recipe_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.recipe_list[item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecipesDataset()\n",
    "recipe_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# tokenizer.add_special_tokens({'end_token': dataset.end_of_text_token})\n",
    "# tokenizer.add_special_tokens({'title_token': dataset.title_token})\n",
    "# tokenizer.add_special_tokens({'review_token': dataset.review_token})\n",
    "# tokenizer.add_special_tokens({'instructions_token': dataset.instructions_token})\n",
    "# tokenizer.add_special_tokens({'rating_token': dataset.rating_token})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_tit Dawn's Sugar Cookies _cat \\n Desserts \\n Cookies \\n Sugar Cookies _ing \\n 1 cup shortening \\n 2 cups white sugar \\n 4 eggs \\n 1 teaspoon vanilla extract \\n 4 cups all-purpose flour \\n 2 teaspoons baking powder \\n 1 teaspoon baking soda \\n 1 cup buttermilk \\n Â½ cup butter, melted \\n 2 cups confectioners' sugar \\n 2 tablespoons milk \\n 3 drops red food coloring _ins Step 1 \\n Preheat oven to 350 degrees F (175 degrees C). Line cookie sheets with parchment paper. \\n Step 2 \\n In a large bowl, cream together the shortening and white sugar until smooth. Beat in eggs one at a time, and stir in vanilla. Combine the flour, baking powder, and baking soda; stir into the creamed mixture alternately with the buttermilk until a soft dough forms. Drop by teaspoonfuls onto prepared cookie sheets. \\n Step 3 \\n Bake for 10 minutes in preheated oven, or until light brown. Cool on wire racks. \\n Step 4 \\n In a medium bowl, blend together melted butter and confectioners' sugar until smooth. Gradually stir in milk until frosting reaches the desired consistency. Mix in food coloring, if desired. Spread onto cooled cookies, and place frosted cookies on waxed paper or cooling racks until frosting is set. \\n _rev This sugar cookie recipe was very good. I used one cup of butter instead of the shortening and I didn't have any buttermilk so I used 3 tablespoons lemon juice and put it in a one cup measuring cup and then filled the rest of the measuring cup up with milk (a buttermilk subsitute) and the cookies turned out great. The only thing that surprised me was that the recipe stated that it makes 2 dozen I ended up with over 40 cookies and had to triple the frosting (and the cookies I made were very large). That's okay because I had plenty to give away to family. Overall it's a very yummy and soft cookie that I will make again. _rat 4 _end\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.recipe_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Desserts', 'Cookies', 'Peanut Butter Cookies']\n",
      "['Desserts', 'Cookies', 'Refrigerator Cookies']\n",
      "['Side Dish', 'Sauces and Condiments', 'Sauces', 'Pasta Sauces', 'Meat Sauce']\n",
      "['Soups, Stews and Chili', 'Soup', 'Vegetable Soup']\n",
      "['Main Dishes', 'Burgers', 'Veggie']\n",
      "['Main Dishes', 'Seafood Main Dishes', 'Crab']\n",
      "['Salad', 'Curry Salad']\n",
      "['Side Dish']\n",
      "['Meat and Poultry', 'Chicken', 'Fried Chicken']\n",
      "['Meat and Poultry', 'Beef', 'Steaks', 'Rib-Eye Steak']\n",
      "['World Cuisine', 'Latin American', 'Mexican']\n",
      "['Soups, Stews and Chili', 'Soup', 'Vegetable Soup']\n",
      "['Desserts', 'Fruit Desserts', 'Apple Desserts']\n",
      "['Bread', 'Yeast Bread']\n",
      "['World Cuisine', 'European', 'Italian']\n",
      "['Side Dish', 'Potato Side Dishes', 'Roasted Potatoes']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['World Cuisine', 'European', 'Eastern European', 'Czech']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Meat and Poultry', 'Pork', 'Pork Ribs', 'Baby Back Ribs']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Desserts', 'Fruit Desserts', 'Strawberry Desserts']\n",
      "['World Cuisine', 'European', 'French']\n"
     ]
    }
   ],
   "source": [
    "recipes_dataset_path = 'C:/Users/Mech Punk/Documents/crawler/allrecipes'\n",
    "recipefiles = [f for f in listdir(recipes_dataset_path) if isfile(join(recipes_dataset_path, f))]\n",
    "recipe_list = []\n",
    "for recipefile in recipefiles:\n",
    "    path = os.path.join(recipes_dataset_path, recipefile)\n",
    "#     print(path)\n",
    "    with open(path) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        for recipe in json_data:\n",
    "            print(recipe[\"recipeCategory\"])\n",
    "            break\n",
    "#             if type(recipe[\"recipeInstructions\"]) == list:\n",
    "#                 recipeInstructions = \"\"\n",
    "#                 for step_index, step in enumerate(recipe[\"recipeInstructions\"]):\n",
    "#                     recipeInstructions += f\"Step {step_index}\\n \" + step.replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
    "#             else:\n",
    "#                 recipeInstructions = (recipe[\"recipeInstructions\"]\n",
    "#             recipe_str = f\"Title {recipe[\"title\"]: {recipeInstructions}}{self.end_of_text_token}\"\n",
    "#             self.recipe_list.append(recipe_str)\n",
    "#             self.recipe_list.append(recipe_str)\n",
    "#             print(len(recipe[\"recipeInstructions\"]))\n",
    "#             print(type(recipe[\"recipeInstructions\"]))\n",
    "#             if type(recipe[\"recipeInstructions\"]) == list and len(recipe[\"recipeInstructions\"]) > 1:\n",
    "#                 break\n",
    "#     if type(recipe[\"recipeInstructions\"]) == list and len(recipe[\"recipeInstructions\"]) > 1:\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For easy cutting line the pan with wax paper or foil. Leave about 1 inch over hang on the ends. Place ingredients inside allow to set as directed. Remove from pan by edges of foil/paper and use a pizza cutter to cut into nice smooth squares. We use this method with all desserts/bars that need to be cut!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe[\"recipeInstructions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipes_dataset_path = 'C:/Users/Mech Punk/Documents/crawler/allrecipes'\n",
    "# recipefiles = [f for f in listdir(recipes_dataset_path) if isfile(join(recipes_dataset_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 0\\n Preheat the oven to 375 degrees F (190 degrees C). Grease a 12 cup muffin tin, or line with paper muffin liners.\\n Step 1\\n In a large bowl, stir together the flour, sugar substitute, baking powder, baking soda, and cinnamon. In a separate bowl, mix together the egg whites, mashed banana and applesauce. Add the wet ingredients to the dry, and mix until just blended. Fill prepared muffin cups 3/4 full.\\n Step 2\\n Bake for 15 to 18 minutes in the preheated oven, or until the top springs back when lightly touched. Allow muffins to cool in the pan over a wire rack for a little while before tapping them out of the pan.\\n '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipeInstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RecipesDataset()\n",
    "recipe_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10809"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([\"Three Cheese Italian Style Chicken Sausage Skillet\" in recipe for recipe in dataset.recipe_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_tit Chocolate Peanut Butter Bars II _cat \\n Desserts \\n Cookies \\n Peanut Butter Cookies _ing \\n Â½ cup butter \\n Â½ cup packed brown sugar \\n 1 teaspoon vanilla extract \\n 2 cups peanut butter \\n 2 Â½ cups confectioners' sugar \\n 2 cups semisweet chocolate chips _ins Step 1 \\n Melt butter or margarine over low heat. Add sugars, peanut butter and vanilla. Mix well. \\n Step 2 \\n Press into a 9 x 13 inch pan. \\n Step 3 \\n Melt chocolate chips and spread over the top. Cool. \\n _rev For easy cutting line the pan with wax paper or foil. Leave about 1 inch over hang on the ends. Place ingredients inside allow to set as directed. Remove from pan by edges of foil/paper and use a pizza cutter to cut into nice smooth squares. We use this method with all desserts/bars that need to be cut! _rat 5 _end\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.recipe_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30630"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.recipe_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "I tested many(more than 5) hyperparameter sets till I found one that works the best. I mostly tuned ***BATCH_SIZE*** (in this case, it's the number of forward-backward passes between each optimization step), ***EOPOCHS***, and ***LEARNING_RATE***.\n",
    "\n",
    "For a parameter value starting point for fine-tuning, I inspired from [this](https://github.com/huggingface/transformers/blob/master/examples/run_squad.py) and [this](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) huggingface fine-tuning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_STEPS = 5000\n",
    "MAX_SEQ_LEN = 800 #400\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup as WarmupLinearSchedule\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "I will train the model and save the model weights after each epoch and then I will try to generate recipes with each version of the weight to see which performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started==============================\n",
      "sum loss 5173.7412109375\n",
      "sum loss 4664.78955078125\n",
      "sum loss 4324.77978515625\n",
      "sum loss 4054.224365234375\n",
      "sum loss 3865.771728515625\n",
      "sum loss 3678.900146484375\n",
      "sum loss 3572.981689453125\n",
      "sum loss 3498.683837890625\n",
      "sum loss 3432.91357421875\n",
      "sum loss 3374.886962890625\n",
      "sum loss 3346.14404296875\n",
      "sum loss 3312.210693359375\n",
      "sum loss 3269.261962890625\n",
      "sum loss 3238.20068359375\n",
      "sum loss 3215.717529296875\n",
      "sum loss 3182.832763671875\n",
      "sum loss 3161.5302734375\n",
      "sum loss 3118.53369140625\n",
      "sum loss 3119.603271484375\n",
      "sum loss 3092.09326171875\n",
      "sum loss 3060.978271484375\n",
      "sum loss 3059.291748046875\n",
      "sum loss 3043.237060546875\n",
      "sum loss 3027.92236328125\n",
      "sum loss 2990.117431640625\n",
      "sum loss 2970.294189453125\n",
      "sum loss 2946.73388671875\n",
      "sum loss 2961.415771484375\n",
      "sum loss 2923.640625\n",
      "sum loss 2934.487548828125\n",
      "sum loss 2920.230712890625\n",
      "sum loss 2897.19287109375\n",
      "sum loss 2862.266357421875\n",
      "sum loss 2872.746337890625\n",
      "sum loss 2856.159912109375\n",
      "sum loss 2846.729736328125\n",
      "sum loss 2855.694091796875\n",
      "sum loss 2811.890869140625\n",
      "sum loss 2805.960205078125\n",
      "sum loss 2784.599365234375\n",
      "sum loss 2792.43115234375\n",
      "sum loss 2797.43994140625\n",
      "sum loss 2754.81787109375\n",
      "sum loss 2764.037353515625\n",
      "sum loss 2765.973876953125\n",
      "sum loss 2747.989990234375\n",
      "sum loss 2715.24365234375\n",
      "sum loss 2735.927734375\n",
      "sum loss 2727.13232421875\n",
      "sum loss 2706.62841796875\n",
      "sum loss 2707.71435546875\n",
      "sum loss 2709.22998046875\n",
      "sum loss 2699.98388671875\n",
      "EPOCH 1 started==============================\n",
      "sum loss 2694.49853515625\n",
      "sum loss 2723.00048828125\n",
      "sum loss 2702.79833984375\n",
      "sum loss 2692.51513671875\n",
      "sum loss 2694.56591796875\n",
      "sum loss 2667.839111328125\n",
      "sum loss 2682.189697265625\n",
      "sum loss 2693.3076171875\n",
      "sum loss 2686.09814453125\n",
      "sum loss 2681.884033203125\n",
      "sum loss 2692.178955078125\n",
      "sum loss 2687.966552734375\n",
      "sum loss 2683.031005859375\n",
      "sum loss 2696.443115234375\n",
      "sum loss 2717.70458984375\n",
      "sum loss 2685.25927734375\n",
      "sum loss 2680.622314453125\n",
      "sum loss 2685.47802734375\n",
      "sum loss 2701.442626953125\n",
      "sum loss 2676.365478515625\n",
      "sum loss 2712.987060546875\n",
      "sum loss 2709.641357421875\n",
      "sum loss 2695.60400390625\n",
      "sum loss 2711.34619140625\n",
      "sum loss 2720.81884765625\n",
      "sum loss 2704.32666015625\n",
      "sum loss 2695.60791015625\n",
      "sum loss 2682.760986328125\n",
      "sum loss 2681.584716796875\n",
      "sum loss 2698.6162109375\n",
      "sum loss 2697.182861328125\n",
      "sum loss 2693.092041015625\n",
      "sum loss 2688.390380859375\n",
      "sum loss 2687.9091796875\n",
      "sum loss 2706.3671875\n",
      "sum loss 2711.78173828125\n",
      "sum loss 2691.59033203125\n",
      "sum loss 2683.126708984375\n",
      "sum loss 2699.776611328125\n",
      "sum loss 2693.022705078125\n",
      "sum loss 2715.097412109375\n",
      "sum loss 2682.301513671875\n",
      "sum loss 2687.86376953125\n",
      "sum loss 2671.20751953125\n",
      "sum loss 2700.266357421875\n",
      "sum loss 2682.31298828125\n",
      "sum loss 2681.17724609375\n",
      "sum loss 2675.982421875\n",
      "sum loss 2680.307861328125\n",
      "sum loss 2706.27197265625\n",
      "sum loss 2697.590576171875\n",
      "sum loss 2688.837890625\n",
      "sum loss 2694.482421875\n",
      "sum loss 2686.423828125\n",
      "EPOCH 2 started==============================\n",
      "sum loss 2687.491455078125\n",
      "sum loss 2677.979248046875\n",
      "sum loss 2687.6923828125\n",
      "sum loss 2689.27001953125\n",
      "sum loss 2693.147216796875\n",
      "sum loss 2676.01611328125\n",
      "sum loss 2700.361083984375\n",
      "sum loss 2692.814208984375\n",
      "sum loss 2715.103271484375\n",
      "sum loss 2670.5322265625\n",
      "sum loss 2709.812744140625\n",
      "sum loss 2685.82080078125\n",
      "sum loss 2697.356689453125\n",
      "sum loss 2687.9248046875\n",
      "sum loss 2700.937744140625\n",
      "sum loss 2707.6171875\n",
      "sum loss 2697.422119140625\n",
      "sum loss 2673.680908203125\n",
      "sum loss 2698.958251953125\n",
      "sum loss 2703.205078125\n",
      "sum loss 2702.98583984375\n",
      "sum loss 2705.530029296875\n",
      "sum loss 2685.127197265625\n",
      "sum loss 2690.643798828125\n",
      "sum loss 2693.709716796875\n",
      "sum loss 2701.079833984375\n",
      "sum loss 2681.299072265625\n",
      "sum loss 2700.18310546875\n",
      "sum loss 2714.575439453125\n",
      "sum loss 2705.884765625\n",
      "sum loss 2697.3740234375\n",
      "sum loss 2692.870361328125\n",
      "sum loss 2696.605712890625\n",
      "sum loss 2704.33837890625\n",
      "sum loss 2696.1357421875\n",
      "sum loss 2682.304931640625\n",
      "sum loss 2699.2119140625\n",
      "sum loss 2673.18212890625\n",
      "sum loss 2689.6025390625\n",
      "sum loss 2691.3447265625\n",
      "sum loss 2704.592041015625\n",
      "sum loss 2676.716552734375\n",
      "sum loss 2705.134765625\n",
      "sum loss 2686.324951171875\n",
      "sum loss 2688.180419921875\n",
      "sum loss 2697.96630859375\n",
      "sum loss 2713.021240234375\n",
      "sum loss 2678.87060546875\n",
      "sum loss 2695.000244140625\n",
      "sum loss 2692.9267578125\n",
      "sum loss 2680.6962890625\n",
      "sum loss 2689.039306640625\n",
      "sum loss 2681.321044921875\n",
      "EPOCH 3 started==============================\n",
      "sum loss 2689.791259765625\n",
      "sum loss 2701.496337890625\n",
      "sum loss 2694.625732421875\n",
      "sum loss 2694.404541015625\n",
      "sum loss 2692.636962890625\n",
      "sum loss 2685.73486328125\n",
      "sum loss 2689.919189453125\n",
      "sum loss 2678.60791015625\n",
      "sum loss 2681.852783203125\n",
      "sum loss 2704.356201171875\n",
      "sum loss 2686.85693359375\n",
      "sum loss 2691.009765625\n",
      "sum loss 2702.018310546875\n",
      "sum loss 2677.35546875\n",
      "sum loss 2694.2744140625\n",
      "sum loss 2701.845703125\n",
      "sum loss 2705.697021484375\n",
      "sum loss 2696.686279296875\n",
      "sum loss 2683.14453125\n",
      "sum loss 2677.247314453125\n",
      "sum loss 2677.90380859375\n",
      "sum loss 2693.123291015625\n",
      "sum loss 2702.9384765625\n",
      "sum loss 2722.623779296875\n",
      "sum loss 2693.589111328125\n",
      "sum loss 2691.274658203125\n",
      "sum loss 2703.35693359375\n",
      "sum loss 2686.354736328125\n",
      "sum loss 2692.934814453125\n",
      "sum loss 2699.64501953125\n",
      "sum loss 2689.78662109375\n",
      "sum loss 2701.464599609375\n",
      "sum loss 2698.5595703125\n",
      "sum loss 2695.821533203125\n",
      "sum loss 2707.28857421875\n",
      "sum loss 2691.617431640625\n",
      "sum loss 2692.296875\n",
      "sum loss 2681.947021484375\n",
      "sum loss 2680.20703125\n",
      "sum loss 2686.678466796875\n",
      "sum loss 2705.121826171875\n",
      "sum loss 2679.771240234375\n",
      "sum loss 2693.77197265625\n",
      "sum loss 2683.271728515625\n",
      "sum loss 2692.367431640625\n",
      "sum loss 2686.116455078125\n",
      "sum loss 2691.22216796875\n",
      "sum loss 2678.919189453125\n",
      "sum loss 2688.7861328125\n",
      "sum loss 2708.205078125\n",
      "sum loss 2699.8408203125\n",
      "sum loss 2678.6708984375\n",
      "sum loss 2697.99169921875\n",
      "sum loss 2693.109130859375\n",
      "EPOCH 4 started==============================\n",
      "sum loss 2706.668701171875\n",
      "sum loss 2684.07373046875\n",
      "sum loss 2691.785400390625\n",
      "sum loss 2709.315185546875\n",
      "sum loss 2701.8720703125\n",
      "sum loss 2698.309814453125\n",
      "sum loss 2699.843017578125\n",
      "sum loss 2678.315673828125\n",
      "sum loss 2696.215087890625\n",
      "sum loss 2694.1025390625\n",
      "sum loss 2702.462158203125\n",
      "sum loss 2687.287841796875\n",
      "sum loss 2700.856689453125\n",
      "sum loss 2691.513427734375\n",
      "sum loss 2694.720947265625\n",
      "sum loss 2713.46826171875\n",
      "sum loss 2690.1435546875\n",
      "sum loss 2670.475341796875\n",
      "sum loss 2704.40869140625\n",
      "sum loss 2689.413330078125\n",
      "sum loss 2718.420166015625\n",
      "sum loss 2701.950439453125\n",
      "sum loss 2712.748779296875\n",
      "sum loss 2703.726318359375\n",
      "sum loss 2694.73291015625\n",
      "sum loss 2712.974609375\n",
      "sum loss 2695.051513671875\n",
      "sum loss 2694.42333984375\n",
      "sum loss 2695.354248046875\n",
      "sum loss 2680.3515625\n",
      "sum loss 2676.36572265625\n",
      "sum loss 2690.737548828125\n",
      "sum loss 2668.751708984375\n",
      "sum loss 2677.670166015625\n",
      "sum loss 2703.5126953125\n",
      "sum loss 2682.433349609375\n",
      "sum loss 2693.35107421875\n",
      "sum loss 2707.45166015625\n",
      "sum loss 2694.8759765625\n",
      "sum loss 2671.74560546875\n",
      "sum loss 2676.525146484375\n",
      "sum loss 2669.295654296875\n",
      "sum loss 2664.7958984375\n",
      "sum loss 2695.5419921875\n",
      "sum loss 2683.9345703125\n",
      "sum loss 2706.71923828125\n",
      "sum loss 2710.67041015625\n",
      "sum loss 2692.942138671875\n",
      "sum loss 2705.845458984375\n",
      "sum loss 2692.6904296875\n",
      "sum loss 2700.437255859375\n",
      "sum loss 2693.184814453125\n",
      "sum loss 2700.1376953125\n",
      "sum loss 2708.092041015625\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = WarmupLinearSchedule(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps = -1)\n",
    "proc_seq_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0\n",
    "\n",
    "tmp_recipes_tens = None\n",
    "models_folder = \"trained_models\"\n",
    "if not os.path.exists(models_folder):\n",
    "    os.mkdir(models_folder)\n",
    "\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "    counter=0\n",
    "    for idx,recipe in enumerate(recipe_loader):\n",
    "#         print(counter)\n",
    "        counter+=1\n",
    "        \n",
    "#         print('a')\n",
    "        \n",
    "        #################### \"Fit as many recipe sequences into MAX_SEQ_LEN sequence as possible\" logic start ####\n",
    "        recipe_tens = torch.tensor(tokenizer.encode(recipe[0])).unsqueeze(0).to(device)\n",
    "        #Skip sample from dataset if it is longer than MAX_SEQ_LEN\n",
    "        if recipe_tens.size()[1] > MAX_SEQ_LEN:\n",
    "            continue\n",
    "            \n",
    "#         print('b')\n",
    "        \n",
    "        #The first recipe sequence in the sequence\n",
    "        if not torch.is_tensor(tmp_recipes_tens):\n",
    "            tmp_recipes_tens = recipe_tens\n",
    "            continue\n",
    "        else:\n",
    "            #The next recipe does not fit in so we process the sequence and leave the last recipe \n",
    "            #as the start for next sequence \n",
    "            if tmp_recipes_tens.size()[1] + recipe_tens.size()[1] > MAX_SEQ_LEN:\n",
    "                work_recipes_tens = tmp_recipes_tens\n",
    "                tmp_recipes_tens = recipe_tens\n",
    "            else:\n",
    "                #Add the recipe to sequence, continue and try to add more\n",
    "                tmp_recipes_tens = torch.cat([tmp_recipes_tens, recipe_tens[:,1:]], dim=1)\n",
    "                continue\n",
    "        ################## Sequence ready, process it trough the model ##################\n",
    "            \n",
    "            \n",
    "#         print('c')\n",
    "        \n",
    "        outputs = model(work_recipes_tens, labels=work_recipes_tens)\n",
    "        loss, logits = outputs[:2]                        \n",
    "        loss.backward()\n",
    "        sum_loss = sum_loss + loss.detach().data\n",
    "                       \n",
    "        proc_seq_count = proc_seq_count + 1\n",
    "        if proc_seq_count == BATCH_SIZE:\n",
    "            proc_seq_count = 0    \n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if batch_count == 100:\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "    \n",
    "    # Store the model after each epoch to compare the performance of them\n",
    "#     torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_medium_reciper_{epoch}.pt\"))\n",
    "    torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_recipe_reviews_ingredients_categories_2_{epoch}.pt\"))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_joker_{epoch}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_seq_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_to_dict(recipe_text):\n",
    "    current = recipe_text.split(\"_tit\")[1]\n",
    "#     print(current)\n",
    "    splitted = current.split(\"_cat \")\n",
    "    (title, current) = splitted[0], splitted[1]\n",
    "#     print(\"title\", title)\n",
    "    splitted = current.split(\"_ing\")\n",
    "    (categories, current) = splitted[0], splitted[1]\n",
    "#     print(\"\\n categories\", ingredients)\n",
    "    splitted = current.split(\"_ins\")\n",
    "    (ingredients, current) = splitted[0], splitted[1]\n",
    "#     print(\"\\n ingredients\", ingredients)\n",
    "    splitted = current.split(\"_rev\")\n",
    "    (instructions, current) = splitted[0], splitted[1]\n",
    "#     print(\"\\n instructions\", instructions)\n",
    "    splitted = current.split(\"_rat\")\n",
    "    (review, current) = splitted[0], splitted[1]\n",
    "#     print(\"\\n review\", review)\n",
    "    splitted = current.split(\"_end\")\n",
    "    (rating, _) = splitted[0], splitted[1]\n",
    "#     print(\"\\n rating\", rating)\n",
    "\n",
    "    categories = [category.strip() for category in categories.strip().split(\"\\n\")]\n",
    "    ingredients = ingredients.strip().replace(\"  \", \" \").split(\"\\n\")\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredients]\n",
    "    instructions = [instruction[2:] for instruction in instructions.strip().replace(\"\\n\",\"\").replace(\"  \", \" \").split(\"Step \")[1:]]\n",
    "    recipe = {\n",
    "        \"title\": title,\n",
    "        \"categories\": categories,\n",
    "        \"ingredients\": ingredients,\n",
    "        \"instructions\": instructions,\n",
    "        \"reviews\": [review],\n",
    "        \"ratings\": [int(rating)],\n",
    "        \n",
    "    }\n",
    "    return recipe\n",
    "# recipe_to_dict(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_recipe_generator(title=\"\", categories=[], ingredients=[], instructions=[], \n",
    "                              number_of_reviews=[5, 10], max_length=1000,\n",
    "                             title_tag=\"_tit\", categories_tag=\"_cat\", ingredients_tag=\"_ing\", instructions_tag=\"_ins\"):\n",
    "    primer = f\"{title_tag} \"+ title\n",
    "    if len(categories) > 0:\n",
    "        primer += f\" {categories_tag} \"\n",
    "        for category in categories:\n",
    "            primer += f\"{category} \\n \"\n",
    "            \n",
    "    if len(ingredients) > 0:\n",
    "        assert len(categories) > 0; \"You need to add categories before ingredients\"\n",
    "        primer += f\"{ingredients_tag} \"\n",
    "        for ingredient in ingredients:\n",
    "            primer += f\"\\n {ingredient} \"\n",
    "           \n",
    "    if len(instructions) > 0:\n",
    "        assert len(ingredients) > 0; \"You need to add ingredients before instructions\"\n",
    "        primer += f\"{instructions_tag} \"\n",
    "        for instruction_index, instruction in enumerate(instructions):\n",
    "            primer += f\"Step {instruction_index+1} \\n {instruction}\" \n",
    "    \n",
    "    output_text, recipe_finished = generate_recipe(primer, max_length=max_length)\n",
    "\n",
    "    # Check if it completed synthesis\n",
    "    if recipe_finished == False:\n",
    "        return None, primer\n",
    "\n",
    "    # Create it into a recipe dictionary\n",
    "    try:\n",
    "        recipe = recipe_to_dict(output_text)\n",
    "    except:\n",
    "        print(\"Recipe is in the wrong format\")\n",
    "        return None, primer\n",
    "        \n",
    "    # Add more reviews\n",
    "    for i in range(np.random.randint(number_of_reviews[0], number_of_reviews[1])):\n",
    "        try:\n",
    "            i_text, recipe_finished = generate_recipe(output_text.split(\"_rev\")[0] + \"_rev\")\n",
    "        except:\n",
    "            print(\"probably recipy too long\")\n",
    "            continue\n",
    "        try:\n",
    "            i_recipe = recipe_to_dict(i_text)\n",
    "            recipe[\"reviews\"].append(i_recipe[\"reviews\"][0])\n",
    "            recipe[\"ratings\"].append(i_recipe[\"ratings\"][0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return recipe, primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe, primer = complete_recipe_generator(\"Apple pie\", \n",
    "                          [\"Desserts\", \"Pies\", \"Apple Pie\"], \n",
    "                          ['1 cup all-purpose flour',\n",
    "                          '1 Â½ teaspoons salt',\n",
    "                          '1 cup white sugar',\n",
    "                          'Â½ cup butter',\n",
    "                          '1 egg',\n",
    "                          '1 Â½ teaspoons vanilla extract',\n",
    "                          '1 teaspoon ground cinnamon',\n",
    "                          '1 cup chopped pecans'],\n",
    "                          [\"If you wish to make apple pie from scratch, you must first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ' Apple pie ',\n",
       " 'categories': ['Desserts', 'Pies', 'Apple Pie'],\n",
       " 'ingredients': ['1 cup all-purpose flour',\n",
       "  '1 Â½ teaspoons salt',\n",
       "  '1 cup white sugar',\n",
       "  'Â½ cup butter',\n",
       "  '1 egg',\n",
       "  '1 Â½ teaspoons vanilla extract',\n",
       "  '1 teaspoon ground cinnamon',\n",
       "  '1 cup chopped pecans'],\n",
       " 'instructions': ['If you wish to make apple pie from scratch, you must first beat the flour and sugar together until well combined. ',\n",
       "  'Preheat oven to 325 degrees F (165 degrees C). ',\n",
       "  'Combine the egg, vanilla, cinnamon, and pecans in a medium bowl and stir into the flour mixture. Stir until well blended. ',\n",
       "  'Pour batter into an ungreased 9x13 inch pan. Bake at 325 degrees F (165 degrees C) for 45 minutes, or until a toothpick inserted into the center of the pie comes out clean.'],\n",
       " 'reviews': [' This is a great recipe for apple pie. I used 1/4 c. butter and 1 1/2 cups white sugar. It was very good. I used a pastry bag instead of an ungreased 9x13 pan and used 1 1/2 c. sugar and 1 1/2 c. applesauce instead of the 1/2 c. butter. I also used a pie pan with a lid on and a lid on the lid. I baked it at 325 for 45 min. and it was still very tender and very moist! ',\n",
       "  \" I am the only one who doesn't like apples so I made this pie. It was delicious. I added a little more cinnamon and a bit of ground nutmeg. I also made the topping with apples and it turned out really good. I will make this again. \",\n",
       "  ' I used 1 cup flour for the filling and 1 cup for the filling. I used 1 cup of applesauce for the topping and 1 cup of butter for the topping. I also added 1 tsp of ground nutmeg and 1 tsp of ground cloves to the batter. The topping was delicious! ',\n",
       "  \" I make this recipe every year for Christmas Eve. It's a big hit! It's easy to make and it's delicious. I use a 9x13 pan. I bake it in a 9x13 pan for 45 minutes. It is a great way to make apples. \",\n",
       "  ' This was very good. The pecans were a nice touch. I used 1/2 cup of butter and it worked out great! I also used 2 cups of white sugar instead of the 2 cups of sugar. ',\n",
       "  ' I had to use a whole lot of flour and sugar to make this. I used a whole cup of white sugar instead of the 1 cup I had on hand and it was a big hit with the whole family. I will be making this again and again. ',\n",
       "  ' I did not have any pecans so I used 1 cup and it was perfect! I used 1/2 cup of white sugar instead of 1 cup of sugar. I also used 2 eggs and 1/2 cup of vanilla. I also added 1/4 cup of ground cinnamon. I also added 1/4 cup of ground nutmeg. I also used 1/2 cup of butter instead of 1 cup and 1/2 cup of sugar. It was perfect! '],\n",
       " 'ratings': [4, 5, 5, 5, 5, 5, 5]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_tit Apple pie _cat Desserts \\n Pies \\n Apple Pie \\n _ing \\n 1 cup all-purpose flour \\n 1 Â½ teaspoons salt \\n 1 cup white sugar \\n Â½ cup butter \\n 1 egg \\n 1 Â½ teaspoons vanilla extract \\n 1 teaspoon ground cinnamon \\n 1 cup chopped pecans _ins Step 1 \\n If you wish to make apple pie from scratch, you must first'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(primer=\"_tit\", max_length=1000):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        recipe_finished = False\n",
    "\n",
    "        cur_ids = torch.tensor(tokenizer.encode(primer)).unsqueeze(0).to(device)\n",
    "\n",
    "        for i in range(max_length):\n",
    "            if cur_ids.shape[1] > max_length:\n",
    "                break\n",
    "            outputs = model(cur_ids, labels=cur_ids)\n",
    "            loss, logits = outputs[:2]\n",
    "            softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n",
    "            if i < 3:\n",
    "                n = 20\n",
    "            else:\n",
    "                n = 3\n",
    "            next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n",
    "            cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n",
    "\n",
    "            if next_token_id in tokenizer.encode('_end'):\n",
    "                recipe_finished = True\n",
    "                break\n",
    "\n",
    "        output_text = \"\"\n",
    "        if recipe_finished:\n",
    "\n",
    "            output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "            output_text = tokenizer.decode(output_list)\n",
    "            # This is just temporary:\n",
    "#             output_text = output_text.replace(\"\\u2009\", '')\n",
    "\n",
    "        return output_text, recipe_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_EPOCH = 4\n",
    "models_folder = \"trained_models\"\n",
    "model_path = os.path.join(models_folder, f\"gpt2_recipe_reviews_ingredients_categories_2_{MODEL_EPOCH}.pt\")\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1de2b28b822a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Generate recipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0moutput_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecipe_finished\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_recipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_tit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Check if it completed synthesis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e47e9fd8e494>\u001b[0m in \u001b[0;36mgenerate_recipe\u001b[1;34m(primer, max_length)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcur_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0msoftmax_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Take the first(from only one in this case) batch and the last predicted embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         )\n\u001b[0;32m    617\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache)\u001b[0m\n\u001b[0;32m    497\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m                 \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m             )\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, layer_past, attention_mask, head_mask, use_cache)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\transformers\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow 2\\lib\\site-packages\\transformers\\activations.py\u001b[0m in \u001b[0;36mgelu_new\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1606.08415\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \"\"\"\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.044715\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "safe_file = 'recipes_3_b.json'\n",
    "\n",
    "try:\n",
    "    with open(safe_file, 'r') as file:\n",
    "        recipes = json.load(file)\n",
    "except:\n",
    "    recipes = []\n",
    "    \n",
    "\n",
    "\n",
    "# model_path = os.path.join(models_folder, f\"gpt2_medium_joker_{MODEL_EPOCH}.pt\")\n",
    "\n",
    "recipes_output_file_path = f'generated_{MODEL_EPOCH}_reviews_ingredients_categories.recipe'\n",
    "\n",
    "model.eval()\n",
    "if os.path.exists(recipes_output_file_path):\n",
    "    os.remove(recipes_output_file_path)\n",
    "    \n",
    "recipe_num = 0\n",
    "for recipe_idx in range(1000):\n",
    "   \n",
    "    # Generate recipe\n",
    "    output_text, recipe_finished = generate_recipe(\"_tit\")\n",
    "\n",
    "    # Check if it completed synthesis\n",
    "    if recipe_finished == False:\n",
    "        continue\n",
    "\n",
    "    # Create it into a recipe dictionary\n",
    "    try:\n",
    "        recipe = recipe_to_dict(output_text)\n",
    "    except:\n",
    "        print(\"Recipe is in the wrong format\")\n",
    "        continue\n",
    "        \n",
    "    # Add more reviews\n",
    "    for i in range(np.random.randint(5,10)):\n",
    "        try:\n",
    "            i_text, recipe_finished = generate_recipe(output_text.split(\"_rev\")[0] + \"_rev\")\n",
    "        except:\n",
    "            print(\"probably recipy too long\")\n",
    "            continue\n",
    "        try:\n",
    "            i_recipe = recipe_to_dict(i_text)\n",
    "            recipe[\"reviews\"].append(i_recipe[\"reviews\"][0])\n",
    "            recipe[\"ratings\"].append(i_recipe[\"ratings\"][0])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    # Add recipe to list\n",
    "    recipe[\"id\"]=f\"{int(time.time())}-{recipe_idx}\"\n",
    "    recipes.append(recipe)\n",
    "    \n",
    "    # Save all recipes\n",
    "    with open(safe_file, 'w') as file:\n",
    "        file.write(json.dumps(recipes, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "        \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Soups, Stews and Chili', 'Soup', 'Vegetable Soup']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ' Baked Zucchini ',\n",
       " 'ingredients': ['2 pounds zucchini, cut into wedges',\n",
       "  '1 cup butter',\n",
       "  '2 eggs',\n",
       "  'Â½ teaspoon salt',\n",
       "  'Â¼ cup milk',\n",
       "  '2 teaspoons ground cumin',\n",
       "  'Â¼ teaspoon ground black pepper',\n",
       "  '1 cup shredded sharp Cheddar cheese',\n",
       "  '1\\u2009Â½ cups shredded Swiss cheese',\n",
       "  '1\\u2009Â½ cups shredded mozzarella cheese'],\n",
       " 'instructions': ['Preheat oven to 400 degrees F (200 degrees C). Grease a 9x13 inch baking dish. ',\n",
       "  'Melt butter in a skillet over medium-high heat. Add eggs one at a time, and saute until lightly browned. Add salt, milk, and cumin. Stir in cheese, and cook until melted and bubbly. ',\n",
       "  'In a large bowl, combine zucchini, melted butter, eggs, salt, and cheese; mix well. Spread into prepared baking dish. ',\n",
       "  'Bake in preheated oven for 30 minutes, or until heated through.'],\n",
       " 'reviews': [' My husband loves this recipe! He has never had zucchini before so I made this for him and he loved it. I used the same recipe as he had but he loved the zucchini and I used a little less cumin and a bit more cheese. I also used 1 1/2 c shredded mozzarella and 1/4 c shredded shredded Monterey Jack cheese. This is a keeper! ',\n",
       "  ' This was very good! I used a little less cream and it was very good! I also used frozen spinach and it was very nice. I will make this one again. '],\n",
       " 'ratings': [5]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_tit Chicken Casserole I _cat \\n Meat and Poultry \\n Chicken \\n Chicken Breasts \\n Skillet _ing \\n 2 (10.75 ounce) cans condensed cream of chicken soup \\n 2 (10.75 ounce) cans condensed cream of mushroom soup \\n 1 (8 ounce) package frozen whipped topping, thawed \\n 1 (8 ounce) package frozen whipped topping, thawed \\n 1 (8 ounce) package frozen chopped spinach, thawed \\n 1 (4 ounce) can sliced green chile peppers, with juice \\n 1 (16 ounce) package shredded Cheddar cheese _ins Step 1 \\n In a large skillet over medium heat, combine soup, mushroom soup, whipped topping and frozen spinach. Cook until spinach is tender, about 10 minutes. Drain and set aside. \\n Step 2 \\n In a large bowl, mix together spinach, green chile pepper, Cheddar cheese and spinach mixture. Pour mixture over chicken and serve. \\n _rev I made this recipe for a party and everyone raved about how it was delicious and easy to make. I used a can of cream of chicken soup and a can of cream of mushroom and it was a hit. I also added some shredded cheddar cheese and some diced onion and it was great. I served it with a side of shredded cheese and a little salsa. _rat 5 _end'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, recipe_finished = generate_recipe(\"_tit\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_tit Chicken Casserole I _cat \\n Meat and Poultry \\n Chicken \\n Chicken Breasts \\n Skillet _ing \\n 2 (10.75 ounce) cans condensed cream of chicken soup \\n 2 (10.75 ounce) cans condensed cream of mushroom soup \\n 1 (8 ounce) package frozen whipped topping, thawed \\n 1 (8 ounce) package frozen whipped topping, thawed \\n 1 (8 ounce) package frozen chopped spinach, thawed \\n 1 (4 ounce) can sliced green chile peppers, with juice \\n 1 (16 ounce) package shredded Cheddar cheese _ins Step 1 \\n In a large skillet over medium heat, combine soup, mushroom soup, whipped topping and frozen spinach. Cook until spinach is tender, about 10 minutes. Drain and set aside. \\n Step 2 \\n In a large bowl, mix together spinach, green chile pepper, Cheddar cheese and spinach mixture. Pour mixture over chicken and serve. \\n _rev'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tit Chicken Casserole I _cat \n",
      " Meat and Poultry \n",
      " Chicken \n",
      " Chicken Breasts \n",
      " Skillet _ing \n",
      " 2 (10.75 ounce) cans condensed cream of chicken soup \n",
      " 2 (10.75 ounce) cans condensed cream of mushroom soup \n",
      " 1 (8 ounce) package frozen whipped topping, thawed \n",
      " 1 (8 ounce) package frozen whipped topping, thawed \n",
      " 1 (8 ounce) package frozen chopped spinach, thawed \n",
      " 1 (4 ounce) can sliced green chile peppers, with juice \n",
      " 1 (16 ounce) package shredded Cheddar cheese _ins Step 1 \n",
      " In a large skillet over medium heat, combine soup, mushroom soup, whipped topping and frozen spinach. Cook until spinach is tender, about 10 minutes. Drain and set aside. \n",
      " Step 2 \n",
      " In a large bowl, mix together spinach, green chile pepper, Cheddar cheese and spinach mixture. Pour mixture over chicken and serve. \n",
      " \n",
      "\n",
      " I made this last night for a family gathering and it was a big hit with everyone. I added some shredded Cheddar cheese and some shredded Cheddar cheese and it was a big hit! _rat 4 _end\n"
     ]
    }
   ],
   "source": [
    "text, recipe_finished = generate_recipe(text.split(\"_rev\")[0] + \"_rev\")\n",
    "a,b = text.split(\"_rev\")\n",
    "print(a)\n",
    "print(\"\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ' Chicken Casserole I ',\n",
       " 'ingredients': ['2 (10.75 ounce) cans condensed cream of chicken soup',\n",
       "  '2 (10.75 ounce) cans condensed cream of mushroom soup',\n",
       "  '1 (8 ounce) package frozen whipped topping, thawed',\n",
       "  '1 (8 ounce) package frozen whipped topping, thawed',\n",
       "  '1 (8 ounce) package frozen chopped spinach, thawed',\n",
       "  '1 (4 ounce) can sliced green chile peppers, with juice',\n",
       "  '1 (16 ounce) package shredded Cheddar cheese'],\n",
       " 'instructions': ['In a large skillet over medium heat, combine soup, mushroom soup, whipped topping and frozen spinach. Cook until spinach is tender, about 10 minutes. Drain and set aside. ',\n",
       "  'In a large bowl, mix together spinach, green chile pepper, Cheddar cheese and spinach mixture. Pour mixture over chicken and serve.'],\n",
       " 'reviews': [' I made this recipe for a party and everyone raved about how it was delicious and easy to make. I used a can of cream of chicken soup and a can of cream of mushroom and it was a hit. I also added some shredded cheddar cheese and some diced onion and it was great. I served it with a side of shredded cheese and a little salsa. '],\n",
       " 'ratings': [5]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = recipe_to_dict(text)\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_title\":\"Grandma Tanya\\'s Chocolate Chip Cookies _cat \\n Desserts \\n Cookies \\n Drop Cookies \\n Chocolate Chip Cookies _ing \\n 1 cup butter \\n 1 cup white sugar \\n Â½ cup packed brown sugar \\n Â½ cup butter, softened \\n 1 teaspoon vanilla extract \\n 1 cup all-purpose flour \\n 1 teaspoon baking soda \\n 1 cup semisweet chocolate chips \\n 2 eggs \\n 1\\u2009â cups confectioners\\' sugar \\n 2 teaspoons vanilla extract \\n 1 cup semisweet chocolate chips _ins Step 1 \\n Preheat oven to 325 degrees F (165 degrees C). Grease cookie sheets. \\n Step 2 \\n Cream the butter or margarine and white sugar. Add the brown sugar and butter. Mix in the vanilla and flour. Stir in the chocolate chips, eggs, confectioners\\' sugar and vanilla until smooth. Drop by rounded teaspoons on cookie sheets. \\n Step 3 \\n Bake for 8 to 10 minutes. Cool on wire racks. \\n Step 4 \\n In a large bowl, beat the chocolate chips and eggs together. Stir in the confectioners\\' sugar and vanilla until smooth. Spread evenly over cookies. \\n _rev'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'le ',\n",
       "  'ingredients': ['2 cups all-purpose flour',\n",
       "   'Â½ teaspoon baking powder',\n",
       "   'Â¾ teaspoon salt',\n",
       "   'Â½ cup white sugar',\n",
       "   '1 egg',\n",
       "   '2 cups rolled oats',\n",
       "   '1 cup butter, melted',\n",
       "   \"1\\u2009Â½ cups confectioners' sugar\"],\n",
       "  'instructions': ['Preheat oven to 350 degrees F (175 degrees C). ',\n",
       "   'In a medium bowl, mix together flour, baking powder and salt. Cut in the white sugar. Stir in eggs one at a time until blended. Stir in the rolled oats. ',\n",
       "   'Drop dough by teaspoonfuls onto ungreased baking sheets. Bake for 8 minutes in the preheated oven. Remove to wire racks to cool completely.'],\n",
       "  'reviews': [' My family and I love these cookies. They are so easy to make. I used 1 cup of flour and 2/3 cup of confectioners sugar. The dough was very soft. I did not have to add any flour. I also added 2 cups of milk to make it more moist. I also used 1/4 cup butter instead of the 2 cups of butter. '],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le-21-11-19 ',\n",
       "  'ingredients': ['2 (10.75 ounce) cans condensed cream of mushroom soup',\n",
       "   'Â½ cup butter',\n",
       "   'Â½ cup white sugar',\n",
       "   '1 tablespoon ground black pepper',\n",
       "   '1 (15 ounce) can chicken broth',\n",
       "   '2 tablespoons all-purpose flour',\n",
       "   '1 teaspoon ground cumin',\n",
       "   '1 teaspoon ground coriander',\n",
       "   '1 teaspoon ground cayenne pepper',\n",
       "   '1 teaspoon salt',\n",
       "   '1 teaspoon dried oregano',\n",
       "   'Â½ teaspoon ground cumin',\n",
       "   '1 teaspoon ground cloves',\n",
       "   '1 teaspoon ground coriander',\n",
       "   '1 teaspoon ground cloves',\n",
       "   '1 teaspoon ground cinnamon'],\n",
       "  'instructions': [\"In a medium saucepan over medium heat, combine soup, butter, sugar, pepper, broth, flour and cumin. Bring to a boil and reduce heat, cover and simmer for 1 1/2 hours or until soup is thick and sauce is thickened and bubbly (see Cook's Note). \",\n",
       "   'Remove from heat and add oregano, cumin, cloves, coriander and cloves. Simmer for 30 minutes, stirring occasionally. ',\n",
       "   'Remove from heat and stir in cinnamon, cayenne pepper, salt and oregano. Cook for 2 to 3 minutes, stirring frequently. Remove from heat and stir in coriander, cloves, cinnamon and cloves. Simmer for 1 1/2 hours or until thickened and bubbly.'],\n",
       "  'reviews': [' This is a great recipe! I used 1 can cream of mushroom soup and 1 cup butter. It was a little bland. I also added 1/2 c. of garlic powder and 1 tsp. of cumin. I also added a little more cayenne than the recipe called for. '],\n",
       "  'ratings': [4]},\n",
       " {'title': 'le = ',\n",
       "  'ingredients': ['1\\u2009Â½ pounds ground beef',\n",
       "   '1 onion, diced',\n",
       "   '1 cup chopped celery',\n",
       "   '1 cup chopped green bell pepper',\n",
       "   '2 tablespoons minced garlic',\n",
       "   '3 tablespoons butter',\n",
       "   '1 cup milk',\n",
       "   '2 teaspoons salt',\n",
       "   'Â½ cup white sugar',\n",
       "   '1 tablespoon all-purpose flour'],\n",
       "  'instructions': ['Preheat the oven to 325 degrees F (165 degrees C). ',\n",
       "   'Cook the beef according to package directions. In a large skillet, saute the onion and celery until tender. Stir in the green pepper and garlic. Cook and stir for 2 minutes, until onions are tender. ',\n",
       "   'In a large mixing bowl, combine the butter, milk and salt; blend well. ',\n",
       "   'Pour the beef mixture into a large, deep skillet and brown over medium high heat, stirring frequently. Add the sugar and flour and heat until thick and bubbly, about 10 minutes. ',\n",
       "   'Stir in the remaining beef mixture and cook until thick and bubbly and browned on all sides. Serve hot.'],\n",
       "  'reviews': [' I used this recipe as a base for the recipe for my husband and I to use up leftover beef from our Thanksgiving dinner. I used the leftover ground beef from our Thanksgiving dinner and used it for the sauce. The sauce was great. I will definitely make this recipe again and again. '],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le ',\n",
       "  'ingredients': ['1 cup butter',\n",
       "   '1 cup white sugar',\n",
       "   '1 cup all-purpose flour',\n",
       "   '1 teaspoon baking soda',\n",
       "   '2 cups all-purpose flour',\n",
       "   '1 teaspoon salt',\n",
       "   '1 teaspoon ground cinnamon',\n",
       "   '1 teaspoon ground cloves',\n",
       "   '1 cup milk',\n",
       "   '1 teaspoon ground nutmeg',\n",
       "   '1 teaspoon ground allspice',\n",
       "   '1 tablespoon ground allspice',\n",
       "   '1 tablespoon ground cloves',\n",
       "   '1 tablespoon butter',\n",
       "   '2 eggs',\n",
       "   '1 cup chopped walnuts',\n",
       "   '1 cup chopped pecans',\n",
       "   '1 cup raisins',\n",
       "   '2 cups raisins',\n",
       "   '2 tablespoons chopped fresh parsley',\n",
       "   '1 cup chopped walnuts',\n",
       "   '1 cup chopped walnuts',\n",
       "   '1 cup chopped walnuts'],\n",
       "  'instructions': ['In a large bowl, cream together butter, sugar and flour until light and fluffy. Stir in the baking soda, all-purpose flour, baking soda and salt. Mix in the milk, nutmeg, allspice and cloves. Beat on low speed until combined. ',\n",
       "   'In a large mixing bowl, beat together the eggs, walnuts, pecans, raisins and parsley. Mix in the walnuts, walnuts and pecans. Mix well and form into walnut halves. Sprinkle evenly over the top of the walnut halves. ',\n",
       "   'Bake in the preheated oven for 30 to 35 minutes, or until the top is golden brown.'],\n",
       "  'reviews': [' I made this last night for the first time and it was a big hit! The only change I made was I used 1/4 cup of butter instead of 1 cup of sugar. I used 1/4 cup butter instead of 1 cup of sugar. I also used 1/2 cup of butter and 1/2 cup of sugar instead of 1/2. It was a big hit with everyone! '],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le ',\n",
       "  'ingredients': ['2 (3.9 ounce) packages orange liqueur',\n",
       "   '2 (6 ounce) packages instant vanilla pudding mix',\n",
       "   '2 cups cold water',\n",
       "   '1\\u2009Â½ cups ice water',\n",
       "   '2 (8 ounce) packages instant vanilla pudding mix'],\n",
       "  'instructions': ['In a large bowl, combine orange liqueur, instant vanilla pudding mix, and water. Mix well and pour into glasses.'],\n",
       "  'reviews': [' This was very good! I made a few modifications. I used a can of frozen lemonade instead of frozen and used 1 cup of water. I used 1 cup of water and 1/2 cup of ice water. I also used a can of frozen whipped cream instead of the instant pudding mix. I also added a little bit of vanilla and a bit of sugar. I think this would make a great gift for friends and family. Thanks for a great recipe. '],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le ',\n",
       "  'ingredients': ['1\\u2009Â½ cups all-purpose flour',\n",
       "   '1 teaspoon salt',\n",
       "   '2 teaspoons baking powder',\n",
       "   '1 teaspoon baking soda',\n",
       "   'Â½ teaspoon salt',\n",
       "   '1 cup shortening',\n",
       "   '2 eggs',\n",
       "   '2 cups milk',\n",
       "   '1 cup butter',\n",
       "   '1 cup white sugar',\n",
       "   '2 cups chopped walnuts'],\n",
       "  'instructions': ['Preheat oven to 350 degrees F (175 degrees C). ',\n",
       "   'In a medium bowl, cream together the shortening and eggs. Stir in the flour, baking powder, baking soda and salt. Sift together the flour mixture, shortening, eggs, milk and butter; stir into flour mixture until just blended. Stir in nuts. Drop by teaspoonfuls onto ungreased cookie sheets. ',\n",
       "   'Bake for 8 to 10 minutes in the preheated oven, until lightly browned. Cool on wire racks.'],\n",
       "  'reviews': [' This is a very good cookie. I used a whole wheat flour and used a 1 1/2 tsp baking powder and 1/4 tsp baking powder. I also added 1/2 tsp salt. It is very easy to make. '],\n",
       "  'ratings': [4]},\n",
       " {'title': 'le = \"A Simple and Easy Chocolate Cake ',\n",
       "  'ingredients': ['1\\u2009Â½ cups all-purpose flour',\n",
       "   '1\\u2009Â½ teaspoons baking powder',\n",
       "   '1\\u2009Â½ teaspoons salt',\n",
       "   '1 teaspoon ground cinnamon',\n",
       "   '1 cup white sugar',\n",
       "   '2 eggs',\n",
       "   '1 cup milk',\n",
       "   '1 cup semisweet chocolate chips',\n",
       "   'Â½ cup butter',\n",
       "   'Â½ cup chopped walnuts',\n",
       "   \"Â¼ cup confectioners' sugar\",\n",
       "   'Â½ teaspoon vanilla extract',\n",
       "   \"Â½ cup confectioners' sugar\"],\n",
       "  'instructions': [\"Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan. In a large bowl, mix together the flour and baking powder. Set aside. In a separate bowl, cream together the white sugar, eggs and milk until light and fluffy. Add the flour mixture alternately with flour mixture alternately with butter, mixing well after each addition. Stir in the chocolate chips, 1/2 cup of the confectioner's sugar, and vanilla until well blended. Spread the batter evenly into prepared pan. \",\n",
       "   'Bake for 35 to 40 minutes in the preheated oven, or until a toothpick inserted into the center of the cake comes out clean. Let cool in pan for 5 minutes, then turn out onto a wire rack. Allow to cool completely. ',\n",
       "   \"To Make Filling: In a large bowl, beat together the butter, confectioners' sugar, and vanilla until smooth. Stir in the confectioners' sugar until just blended. Spread evenly into the prepared pan.\"],\n",
       "  'reviews': [\" I made this cake for my son's birthday party last year. It turned out great. The cake was a bit dry and I used a bit more flour than called for and the cake was still very moist. The icing was very sweet and I didn't have any nuts on hand so I used walnuts instead. The icing was very moist and I will definitely make again. \"],\n",
       "  'ratings': [4]},\n",
       " {'title': 'le ',\n",
       "  'ingredients': ['1 pound ground beef',\n",
       "   '2 cloves garlic, minced',\n",
       "   '2 tablespoons olive oil',\n",
       "   '2 tablespoons dried oregano',\n",
       "   'Â½ teaspoon ground cumin',\n",
       "   '1 teaspoon salt',\n",
       "   '1 tablespoon chopped black pepper',\n",
       "   '2 tablespoons chopped fresh cilantro',\n",
       "   'Â½ teaspoon ground black pepper'],\n",
       "  'instructions': ['Preheat grill for medium-high heat. Lightly oil grate. ',\n",
       "   'Combine ground beef, garlic, olive oil, oregano, cumin, salt, pepper, and cilantro in a large bowl. Mix well. ',\n",
       "   'Place meat mixture in a large resealable plastic bag. Place bag in preheated oven. Cook for 1 to 2 minutes on each side, or until meat is no longer pink and juices run clear.'],\n",
       "  'reviews': [' I used ground beef instead of ground beef and added 1/2 c cayenne pepper to the meat. I used 1/2 c cayenne pepper and 1/2 c garlic. I also used fresh basil and 1/2 c cumin. I also used a can of diced tomatoes and a can of diced red bell pepper. I served with the chili. I also used a can of diced red bell pepper and a can of diced red bell pepper. I served it with a can of diced green chile peppers. '],\n",
       "  'ratings': [4]},\n",
       " {'title': 'le \"The Art of the Chessboard Chessboard\" ',\n",
       "  'ingredients': ['1 cup milk',\n",
       "   '1 cup white sugar',\n",
       "   '1 cup all-purpose flour',\n",
       "   '1 teaspoon ground nutmeg',\n",
       "   '1 teaspoon salt',\n",
       "   '1 egg, beaten',\n",
       "   '1 cup white sugar',\n",
       "   '1 teaspoon ground cinnamon',\n",
       "   '1 teaspoon ground nutmeg',\n",
       "   '1 teaspoon ground ginger',\n",
       "   'Â½ teaspoon ground cloves',\n",
       "   '2 tablespoons butter, softened',\n",
       "   '1 (16 ounce) can crushed pineapple with juice',\n",
       "   '1 cup white sugar',\n",
       "   '1 tablespoon ground cinnamon'],\n",
       "  'instructions': ['Place milk and sugar in a saucepan over medium heat. Bring to a boil, and cook until sugar is dissolved, about 10 minutes. Stir in flour, nutmeg, salt, egg, and 1 cup white sugar. Cook, stirring constantly, until thickened, about 1 minute. Remove from heat. ',\n",
       "   'Stir in 1 cup white sugar and cinnamon. Cook, stirring constantly, until mixture is thickened. Stir in crushed pineapple with juice and 1 cup white sugar. Stir in 1 cup white sugar and 1 tablespoon of cinnamon. Reduce heat, cover, and simmer until thickened. Stir in 1 cup white sugar and 1 tablespoon of cinnamon. ',\n",
       "   'Remove from heat, and serve hot.'],\n",
       "  'reviews': [\" I made this for a family dinner. It was very tasty! I did make a few changes. I used 1 cup white sugar instead of 1 cup white sugar and I used 1 cup of crushed pineapple instead of 1 cup white sugar. It was a little too sweet for my taste. I also added 1/2 cup sugar and 1/3 cup of ground cinnamon. I think it's best if you use the whole thing. It was very good. \"],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le ',\n",
       "  'ingredients': ['1 (3 ounce) can crushed ice',\n",
       "   '1 (8 ounce) can crushed pineapple with juice',\n",
       "   '2 (8 ounce) cans mandarin oranges, drained',\n",
       "   '1 (8 ounce) can pineapple juice concentrate'],\n",
       "  'instructions': ['Pour crushed ice into a large punchbowl, and pour pineapple juice concentrate over the ice. Chill for at least one hour. Pour into a cocktail glass.'],\n",
       "  'reviews': [\" I made this recipe for a party and I was a bit nervous. I didn't have any mandarin oranges so I added 1 1/2 cans pineapple juice concentrate. It was delicious and it was a big hit. I also used pineapple with a little less pineapple juice concentrate and a bit more mandarin oranges. I will definately make again! Thanks! \"],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le\\n\\nHalloween Specials ',\n",
       "  'ingredients': ['Â½ cup butter, softened',\n",
       "   '1 egg',\n",
       "   'Â½ cup white sugar',\n",
       "   '1\\u2009Â¼ cups all-purpose flour',\n",
       "   '1 teaspoon baking powder',\n",
       "   '1 teaspoon salt',\n",
       "   'Â½ cup butter, softened',\n",
       "   '1 teaspoon vanilla extract',\n",
       "   'Â½ cup chopped walnuts',\n",
       "   'Â½ cup chopped pecans',\n",
       "   'Â½ cup chopped walnuts',\n",
       "   'Â½ cup chopped pecans',\n",
       "   'Â½ cup chopped walnuts',\n",
       "   '1 cup chopped walnuts',\n",
       "   'Â½ cup chopped walnuts',\n",
       "   '1 cup chopped walnuts',\n",
       "   '1 teaspoon vanilla extract'],\n",
       "  'instructions': ['Preheat oven to 375 degrees F (190 degrees C). ',\n",
       "   'In a medium bowl, cream together the butter, 1 egg and sugar until light and fluffy. Stir in the flour, baking powder and salt. Combine the butter mixture with 1 1/2 cups chopped nuts and 1 teaspoon of walnuts; mix well. Stir in the melted butter mixture and 1 1/2 cups chopped nuts. Drop by rounded spoonfuls 1 inch apart onto ungreased cookie sheets. ',\n",
       "   'Bake for 10 minutes in the preheated oven. Remove from baking sheets to cool on wire racks.'],\n",
       "  'reviews': [\" I made this for a party and everyone loved it. I used a little bit more butter but it worked out well. I also used 1/2 cup chopped pecans and a little less walnuts. I also cut the walnuts in half so I didn't need to cut them in half. It was a great recipe. Thanks so much. \"],\n",
       "  'ratings': [5]},\n",
       " {'title': 'le\":\"Grandma Tanya\\'s Chocolate Chip Cookies ',\n",
       "  'ingredients': ['1 cup butter',\n",
       "   '1 cup white sugar',\n",
       "   'Â½ cup packed brown sugar',\n",
       "   'Â½ cup butter, softened',\n",
       "   '1 teaspoon vanilla extract',\n",
       "   '1 cup all-purpose flour',\n",
       "   '1 teaspoon baking soda',\n",
       "   '1 cup semisweet chocolate chips',\n",
       "   '2 eggs',\n",
       "   \"1\\u2009â cups confectioners' sugar\",\n",
       "   '2 teaspoons vanilla extract',\n",
       "   '1 cup semisweet chocolate chips'],\n",
       "  'instructions': ['Preheat oven to 325 degrees F (165 degrees C). Grease cookie sheets. ',\n",
       "   \"Cream the butter or margarine and white sugar. Add the brown sugar and butter. Mix in the vanilla and flour. Stir in the chocolate chips, eggs, confectioners' sugar and vanilla until smooth. Drop by rounded teaspoons on cookie sheets. \",\n",
       "   'Bake for 8 to 10 minutes. Cool on wire racks. ',\n",
       "   \"In a large bowl, beat the chocolate chips and eggs together. Stir in the confectioners' sugar and vanilla until smooth. Spread evenly over cookies.\"],\n",
       "  'reviews': [' This was really good. I made a few changes to make them even better. I used 1 cup of brown sugar instead of 2 1/2 cups of white sugar and 1 cup of brown sugar instead of 1 1/2 cup of butter. I also used 1/2 cup of chocolate chips. I also used 1 1/2 cups of semisweet chips instead of 1 cup of white. It made them even better and they were still soft and chewy. '],\n",
       "  'ratings': [5]}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's make some freaking apple pi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Apple pie\", \n",
    "#                           [\"Desserts\", \"Pies\", \"Apple Pie\"], \n",
    "#                           [])\n",
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Apple pie\", \n",
    "#                           [\"Desserts\", \"Pies\", \"Apple Pie\"], \n",
    "#                           ['1 cup all-purpose flour',\n",
    "#                           '1 Â½ teaspoons salt',\n",
    "#                           '1 cup white sugar',\n",
    "#                           'Â½ cup butter',\n",
    "#                           '1 egg',\n",
    "#                           '1 Â½ teaspoons vanilla extract',\n",
    "#                           '1 teaspoon ground cinnamon',\n",
    "#                           '1 cup chopped pecans'],\n",
    "#                           [\"If you wish to make apple pie from scratch, you must first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Space cake _cat\")\n",
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Cream pie _cat\")\n",
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Dead rat _cat\")\n",
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe, primer = complete_recipe_generator(\"Guinea pig _cat\")\n",
    "# recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_file = 'recipes_custom.json'\n",
    "\n",
    "try:\n",
    "    with open(safe_file, 'r') as file:\n",
    "        recipes = json.load(file)\n",
    "except:\n",
    "    recipes = []\n",
    "\n",
    "\n",
    "# Add recipe to list\n",
    "recipe[\"id\"]=f\"{int(time.time())}-C\"\n",
    "recipes.append(recipe)\n",
    "\n",
    "# Save all recipes\n",
    "with open(safe_file, 'w') as file:\n",
    "    file.write(json.dumps(recipes, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"Preheat oven to 325 degrees F (165 degrees C). Lightly grease cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15747, 13]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = tokenizer.encode(\" sheets.\")\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6719,\n",
       " 25080,\n",
       " 14361,\n",
       " 284,\n",
       " 29524,\n",
       " 7370,\n",
       " 376,\n",
       " 357,\n",
       " 20986,\n",
       " 7370,\n",
       " 327,\n",
       " 737,\n",
       " 4401,\n",
       " 306,\n",
       " 35537,\n",
       " 19751]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary  = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_dictionary = {}\n",
    "for key in dictionary:\n",
    "    value = dictionary[key]\n",
    "    inverse_dictionary[value]=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre 6719\n",
      "heat 25080\n",
      "Ä oven 14361\n",
      "Ä to 284\n",
      "Ä 325 29524\n",
      "Ä degrees 7370\n",
      "Ä F 376\n",
      "Ä ( 357\n",
      "165 20986\n",
      "Ä degrees 7370\n",
      "Ä C 327\n",
      "). 737\n",
      "Ä Light 4401\n",
      "ly 306\n",
      "Ä grease 35537\n",
      "Ä cookie 19751\n"
     ]
    }
   ],
   "source": [
    "for code in encoded:\n",
    "    print(inverse_dictionary[code], code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6719, 25080, 14361, 284, 29524, 7370, 376, 357, 20986, 7370, 327, 737, 4401, 306, 35537, 19751, -> 15747'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_do = \"\"\n",
    "for code in encoded:\n",
    "    to_do+=f\"{code}, \"\n",
    "to_do+=f\"-> {to_predict[0]}\"\n",
    "to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ids = torch.tensor(encoded).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6719, 25080, 14361,   284, 29524,  7370,   376,   357, 20986,  7370,\n",
       "           327,   737,  4401,   306, 35537, 19751]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(cur_ids, labels=cur_ids)\n",
    "    loss, logits = outputs[:2]\n",
    "    softmax_logits = torch.softmax(logits[0,-1], dim=0) \n",
    "    output = softmax_logits.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(output,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibilities = (output > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9629],\n",
       "       [15747]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(output > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ä sheets'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_dictionary[15747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ä sheet'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_dictionary[9629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9629, 15747], dtype=int64),)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(output > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185744"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[15747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076905936"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[9629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2') \n",
    "word_embeddings = model.transformer.wte.weight \n",
    "# position_embeddings = model.transformer.wpe.weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embedding_matrix = word_embeddings.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_token = dictionary[\"man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_vector = embedding_matrix[man_token,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_token = dictionary[\"woman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_vector = embedding_matrix[woman_token,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_token = dictionary[\"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_vector = embedding_matrix[car_token,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18a7a76a688>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(man_vector[:10], '.')\n",
    "plt.plot(woman_vector[:10], '.')\n",
    "plt.plot(car_vector[:10], '.')\n",
    "plt.legend([\"man\",\"woman\",\"car\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_token = dictionary[\"king\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector = embedding_matrix[king_token,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_queen_vector = king_vector - man_vector + woman_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_queen_difference_matrix = embedding_matrix - maybe_queen_vector[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_queen_differences = np.sum(np.abs(maybe_queen_difference_matrix),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maybe_queen_indices, maybe_queen_values = np.argsort(maybe_queen_differences, ), np.sort(maybe_queen_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman', 'ked', 'KING', 'women', 'King', 'Lady', 'Ä', 'Ä', 'Ã©Â¾Ä¯Ã¥Â¥']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inverse_dictionary[key] for key in maybe_queen_indices[1:10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['planes',\n",
       " 'Ä plane',\n",
       " 'Ä planes',\n",
       " 'Ä Plane',\n",
       " 'Ä airplane',\n",
       " 'Ä aircraft',\n",
       " 'Ä airplanes',\n",
       " 'Ä jet',\n",
       " 'Ä']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_token = dictionary[\"plane\"]\n",
    "probe_vector = embedding_matrix[probe_token,:]\n",
    "probe_difference_matrix = embedding_matrix - probe_vector[np.newaxis,:]\n",
    "probe_differences = np.sum(np.abs(probe_difference_matrix),axis=1)\n",
    "probe_indices, probe_values = np.argsort(probe_differences, ), np.sort(probe_differences)\n",
    "[inverse_dictionary[key] for key in probe_indices[1:10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(probe):\n",
    "    probe_token = dictionary[probe]\n",
    "    probe_vector = embedding_matrix[probe_token,:]\n",
    "    probe_difference_matrix = embedding_matrix - probe_vector[np.newaxis,:]\n",
    "    probe_differences = np.sum(np.abs(probe_difference_matrix),axis=1)\n",
    "    probe_indices, probe_values = np.argsort(probe_differences, ), np.sort(probe_differences)\n",
    "    return [inverse_dictionary[key] for key in probe_indices[1:10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['planes',\n",
       " 'Ä plane',\n",
       " 'Ä planes',\n",
       " 'Ä Plane',\n",
       " 'Ä airplane',\n",
       " 'Ä aircraft',\n",
       " 'Ä airplanes',\n",
       " 'Ä jet',\n",
       " 'Ä']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat', 'cats', 'Ä cat', 'Ä Cat', 'Ä cats', 'c', 'Ã¸', 'Ä', 'Ä']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dogs', 'Ä dog', 'Dog', 'Ä Dog', 'Ä dogs', 'Ä Dogs', 'Ä', 'Ã', 'Ãº']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ä building',\n",
       " 'builders',\n",
       " 'Building',\n",
       " 'Ä Building',\n",
       " 'builder',\n",
       " 'build',\n",
       " 'Ä constructing',\n",
       " 'Ä builders',\n",
       " 'Ä build']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"building\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['houses',\n",
       " 'Ä house',\n",
       " 'House',\n",
       " 'Ä House',\n",
       " 'Ä houses',\n",
       " 'Ä HOUSE',\n",
       " 'Ä in',\n",
       " 'Ä and',\n",
       " 'Ä with']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer',\n",
       " 'Ä computer',\n",
       " 'Ä Computer',\n",
       " 'Ä computers',\n",
       " 'Ä computational',\n",
       " 'Ãº',\n",
       " 'Ä',\n",
       " 'Ã¼',\n",
       " 'Ä']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest(\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" \".join([\"hi\" for _ in range(1024)])\n",
    "\n",
    "encoded = tokenizer.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ids = torch.tensor(encoded).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.1368643e-05, 2.8269228e-06, 5.0701726e-07, ..., 4.2566777e-09,\n",
       "       9.8345931e-10, 3.1883785e-05], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(cur_ids, labels=cur_ids)\n",
    "    loss, logits = outputs[:2]\n",
    "    softmax_logits = torch.softmax(logits[0,-1], dim=0) \n",
    "    output = softmax_logits.to('cpu').numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51463168"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50257 * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
